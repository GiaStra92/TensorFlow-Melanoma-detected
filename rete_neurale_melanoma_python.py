# -*- coding: utf-8 -*-
"""rete_neurale_melanoma.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aMxMXI6WiQwL7fB1bNPFuC3gmWcwTEyZ

download dataset with your api key kaggle. The api key is free
"""

!pip install opendatasets

import opendatasets as od
import pandas

od.download(
	"https://www.kaggle.com/datasets/drscarlat/melanoma")

import os
# importante rinominare path melanoma/DermMel/train_sep in :
# /content/melanoma/DermMel/train




import os

current_path = '/content/melanoma/DermMel/train_sep'
new_path = '/content/melanoma/DermMel/train'

if not os.path.exists(new_path):

    os.rename(current_path, new_path)
    print(f"La cartella è stata rinominata da {current_path} a {new_path}")
else:
    print(f"Il percorso di destinazione {new_path} esiste già. Non è necessario rinominare la cartella.")





# cartelle di apprendimento e validazione

base_dir = '/content/melanoma/DermMel'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'valid')

# puntiamo alle cartelle di Melanoma e NotMelanoma per il training
train_Melanoma_dir = os.path.join(train_dir, 'Melanoma')
train_NotMelanoma_dir = os.path.join(train_dir, 'NotMelanoma')

# puntiamo alle cartelle di Melanoma e NotMelanoma per la validazione
validation_Melanoma_dir = os.path.join(validation_dir, 'Melanoma')
validation_NotMelanoma_dir = os.path.join(validation_dir, 'NotMelanoma')





import tensorflow as tf

    # Creiamo un modello sequenziale
model = tf.keras.models.Sequential([
    # Primo strato di convoluzione con 16 filtri 3x3, attivazione ReLU e dimensione dell'input 150x150x3
    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),

    # Strato di MaxPooling 2x2
    tf.keras.layers.MaxPooling2D(2,2),

    # Secondo strato di convoluzione con 32 filtri 3x3 e attivazione ReLU
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),

    # Altro strato di MaxPooling 2x2
    tf.keras.layers.MaxPooling2D(2,2),

    # Terzo strato di convoluzione con 64 filtri 3x3 e attivazione ReLU
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),

    # Ulteriore strato di MaxPooling 2x2
    tf.keras.layers.MaxPooling2D(2,2),

    # Appiattiamo il risultato per passarlo ad uno strato denso
    tf.keras.layers.Flatten(),

    # Strato denso con 512 neuroni e attivazione ReLU
    tf.keras.layers.Dense(512, activation='relu'),

    # Strato di output con un singolo neurone e attivazione sigmoide
    tf.keras.layers.Dense(1, activation='sigmoid')
    #output 0 benigno 1 maligno
])

# Visualizziamo una panoramica del modello
model.summary()

# optimizer="adam": Questo parametro specifica l'algoritmo di ottimizzazione da utilizzare.
# L'ottimizzatore "Adam" è una scelta popolare perché funziona bene in molte situazioni.
# L'ottimizzatore è responsabile dell'aggiornamento dei pesi della rete durante l'addestramento
# per ridurre l'errore di previsione.

# loss='binary_crossentropy': Qui specifichi la funzione di perdita, che è un modo per misurare
# quanto bene il modello sta facendo le sue previsioni. Nel caso della 'binary_crossentropy',
# è usata per problemi di classificazione binaria, dove devi decidere tra due opzioni (come "sì" o "no").
# nel nostro caso 0,1 'benigno', 'maligno'
# metrics=['accuracy']: Questo parametro definisce le metriche da utilizzare per valutare le prestazioni del modello.
# "Accuracy" è una metrica comune, che misura la percentuale di previsioni corrette del modello.





model.compile(optimizer="adam",
              loss='binary_crossentropy',
              metrics = ['accuracy'])

from tensorflow.keras.preprocessing.image import ImageDataGenerator


# riscaliamo tutte le nostre immagini con il parametro rescale
train_datagen = ImageDataGenerator(rescale = 1.0/255)
test_datagen  = ImageDataGenerator(rescale = 1.0/255)

# utilizziamo flow_from_directory per creare un generatore per il training
train_generator = train_datagen.flow_from_directory(train_dir,
                                                    batch_size=20,
                                                    class_mode='binary',
                                                    target_size=(150, 150))

# utilizziamo flow_from_directory per creare un generatore per la validazione
validation_generator =  test_datagen.flow_from_directory(validation_dir,
                                                         batch_size=20,
                                                         class_mode='binary',
                                                         target_size=(150, 150))

history = model.fit(
    train_generator, # generatore per il training
    steps_per_epoch=334, # numero  di steps per epoca basato sul batch size
    epochs=15, # numero di epoche
    validation_data=validation_generator, # generatore per la validazione
    validation_steps=111, # numero  di steps per epoca di validazione basato sul batch size
    verbose=2 # livello di verbosità
)

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image



# Estrai i modelli per gli strati convoluzionali
layer_outputs = [layer.output for layer in model.layers[:4]] # Modifica in base ai tuoi strati
activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)
base_dir = '/content/melanoma/DermMel/valid/Melanoma/AUG_0_1833.jpeg'
# Carica l'immagine da visualizzare
img = image.load_img(base_dir, target_size=(150, 150))
img_tensor = image.img_to_array(img)
img_tensor = np.expand_dims(img_tensor, axis=0)
img_tensor /= 255.0

# Calcola le attivazioni
activations = activation_model.predict(img_tensor)

# Funzione per visualizzare le attivazioni
def display_activation(activations, col_size, row_size, act_index):
    activation = activations[act_index]
    # Ottieni il numero di filtri nello strato
    num_filters = activation.shape[-1]

    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))
    for row in range(row_size):
        for col in range(col_size):
            ax[row][col].imshow(activation[0, :, :, row * col_size + col], cmap='viridis')
            if row * col_size + col + 1 == num_filters:
                # Interrompi se hai raggiunto il numero di filtri

                return

# visualizzare le attivazioni
display_activation(activations, col_size=4, row_size=4, act_index=1)

import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

# Plottiamo la accuracy con un grafico a punti
plt.scatter(epochs, acc, label='Training Accuracy')
plt.scatter(epochs, val_acc, label='Validation Accuracy')
plt.title('Accuracy in training e validazione')
plt.legend()
plt.show()

# Creiamo un nuovo grafico per la loss a punti
plt.scatter(epochs, loss, label='Training Loss')
plt.scatter(epochs, val_loss, label='Validation Loss')
plt.title('Loss in training e validazione')
plt.legend()
plt.show()

from google.colab import drive
drive.mount('/content/drive')

# qui possiamo salvare il nostro modello se vogliamo :

from keras.models import Sequential



directory_path = "/content/save_model"

# Verifica se la directory esiste già per evitare errori
if not os.path.exists(directory_path):
    os.makedirs(directory_path)
    print(f"Directory '{directory_path}' creata con successo.")
else:
    print(f"La directory '{directory_path}' esiste già.")



model.save('/content/save_model/rete-neurale_model.h5')

import numpy as np
from keras.preprocessing import image
import tensorflow as tf



# Inserimento manuale del percorso dell'immagine
path = input("Inserisci il percorso dell'immagine: ")

# Caricamento e preparazione dell'immagine
img = image.load_img(path, target_size=(150, 150))  # Scala l'immagine alla dimensione target
x = image.img_to_array(img)  # Converte l'immagine in un array
x /= 255  # Normalizza i valori dei pixel
x = np.expand_dims(x, axis=0)  # Aggiungi una dimensione per adattarsi all'input del modello
model_path = '/content/save_model/rete-neurale_model.h5'

# model = load_model('/content/save_model/rete-neurale_model.h5')
model = tf.keras.models.load_model(model_path)

# Esecuzione della predizione
classes = model.predict(x, batch_size=10)

print(classes[0])

# Interpretazione del risultato
if classes[0] > 0.5:
    print(path.split("/")[-1] + " è benigno!")
else:
    print(path.split("/")[-1] + " è maligno!")